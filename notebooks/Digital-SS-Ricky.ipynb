{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b10ee9fa",
   "metadata": {},
   "source": [
    "## TP Digital Social Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02858d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: numpy in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (2.3.4)\n",
      "Requirement already satisfied: numpy in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (2.3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas \n",
    "!pip install numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29eb0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy  as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2837741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv/train.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da9675e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "435d44bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77238081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - is the opening only supposed to mention significant aspects, or the \"\"most significant\"\" ones?   \\n\\n\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61.19.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  \\\n",
       "0       0000997932d777bf   \n",
       "1       000103f0d9cfb60f   \n",
       "2       000113f07ec002fd   \n",
       "3       0001b41b1c6bb37e   \n",
       "4       0001d958c54c6e35   \n",
       "...                  ...   \n",
       "159566  ffe987279560d7ff   \n",
       "159567  ffea4adeee384e90   \n",
       "159568  ffee36eab5c267c9   \n",
       "159569  fff125370e4aaaf3   \n",
       "159570  fff46fc426af1f9a   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              comment_text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ...   \n",
       "159566                                                                                                                                                                                                                                                                                                                                           \":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - is the opening only supposed to mention significant aspects, or the \"\"most significant\"\" ones?   \\n\\n\"   \n",
       "159567                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61.19.93   \n",
       "159568                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.   \n",
       "159569                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.   \n",
       "159570                                                                                                                                                                                                                                                                                                                                                                                                                                                      \"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0f2b8a",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8914ab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: click in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from nltk) (2025.10.23)\n",
      "Requirement already satisfied: tqdm in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from nltk) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "### NLTK\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "762870cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/romarickaki/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/romarickaki/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/romarickaki/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/romarickaki/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/romarickaki/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /Users/romarickaki/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/romarickaki/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/romarickaki/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "#tokenisation\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "#stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# entity\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')\n",
    "\n",
    "#lemma\n",
    "nltk.download(\"wordnet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e859b0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:30: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/2f/7pvx4z156c3f2my6cs4gd9l00000gn/T/ipykernel_18873/303575219.py:30: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  s = PHONE_RE.sub(lambda m: '<PHONE>' if len(re.sub('[^\\d]', '', m.group(0))) >= 6 else m.group(0), s)\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/romarickaki/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/romarickaki/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/romarickaki/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/romarickaki/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Anonymisation - mask personal data in `comment_text` using regex + NLTK NE chunking\n",
    "import re\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk import ne_chunk\n",
    "\n",
    "# Ensure necessary NLTK data is present\n",
    "for pkg in ['punkt', 'averaged_perceptron_tagger', 'maxent_ne_chunker', 'words']:\n",
    "    try:\n",
    "        nltk.data.find(pkg)\n",
    "    except Exception:\n",
    "        nltk.download(pkg)\n",
    "\n",
    "# Regex patterns for common PII\n",
    "EMAIL_RE = re.compile(r'\\b[-]+@[-]+\\.{2,}\b', flags=re.IGNORECASE)\n",
    "PHONE_RE = re.compile(r'(?:\\+?\\d{1,3}[.-])?(?:\\(?\\d{2,4}\\)?[.-])?[\\d.-]{6,15}')\n",
    "CREDIT_RE = re.compile(r'\\b(?:\\d[ -]*?){13,16}\\b')\n",
    "DATE_RE = re.compile(r'\\b(?:\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|\\d{4}[/-]\\d{1,2}[/-]\\d{1,2}|\\d{1,2}\\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec)[a-z]*\\s+\\d{2,4})\\b', flags=re.IGNORECASE)\n",
    "AGE_RE = re.compile(r'\\b(?:age\\s*[:]?\\s*\\d{1,3}|\\d{1,3}\\s?(?:years?\\sold|yo|y/o|yrs|ans))\\b', flags=re.IGNORECASE)\n",
    "# simple address pattern: number + street type (may not catch all addresses)\n",
    "ADDRESS_RE = re.compile(r'\\b\\d{1,5}\\s+(?:[\\w\\s]{1,60}?)\\s+(?:Street|St|Avenue|Ave|Road|Rd|Boulevard|Blvd|Lane|Ln|Drive|Dr|Way|Court|Ct|Square|Sq)\\b', flags=re.IGNORECASE)\n",
    "\n",
    "# Helper to mask regex PII\n",
    "def mask_regex_pii(text):\n",
    "    s = text\n",
    "    s = EMAIL_RE.sub('<EMAIL>', s)\n",
    "    s = CREDIT_RE.sub('<CREDIT_CARD>', s)\n",
    "    # Phone pattern can be noisy; only mask long digit sequences (6+ digits)\n",
    "    s = PHONE_RE.sub(lambda m: '<PHONE>' if len(re.sub('[^\\d]', '', m.group(0))) >= 6 else m.group(0), s)\n",
    "    s = DATE_RE.sub('<DATE>', s)\n",
    "    s = AGE_RE.sub('<AGE>', s)\n",
    "    s = ADDRESS_RE.sub('<ADDRESS>', s)\n",
    "    return s\n",
    "\n",
    "# Use NLTK NE chunking to find PERSON / GPE / LOCATION entities and mask them\n",
    "def mask_named_entities(text):\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        tags = pos_tag(tokens)\n",
    "        tree = ne_chunk(tags, binary=False)\n",
    "    except Exception:\n",
    "        return text, []\n",
    "    found = []\n",
    "    for subtree in tree:\n",
    "        if hasattr(subtree, 'label'):\n",
    "            label = subtree.label()\n",
    "            ent = ' '.join([tok for tok, pos in subtree.leaves()])\n",
    "            if label in ('PERSON', 'GPE', 'LOCATION', 'ORGANIZATION'):\n",
    "                # replace whole-word occurrences (case-insensitive)\n",
    "                try:\n",
    "                    pattern = re.compile(r'\\b' + re.escape(ent) + r'\\b', flags=re.IGNORECASE)\n",
    "                    if label == 'PERSON':\n",
    "                        text = pattern.sub('<PERSON>', text)\n",
    "                    else:\n",
    "                        text = pattern.sub('<' + label + '>', text)\n",
    "                    found.append((ent, label))\n",
    "                except re.error:\n",
    "                    # skip problematic entity regexes\n",
    "                    pass\n",
    "    return text, found\n",
    "\n",
    "def mask_personal_info(text):\n",
    "    if not isinstance(text, str):\n",
    "        return '', []\n",
    "    # first mask regex-based PII\n",
    "    s = mask_regex_pii(text)\n",
    "    # then mask named entities from NLTK\n",
    "    s, ents = mask_named_entities(s)\n",
    "    return s, ents\n",
    "\n",
    "# Apply to the DataFrame `df` (assumes df already loaded with 'comment_text')\n",
    "if 'comment_text' not in globals() and 'df' in globals() and 'comment_text' in df.columns:\n",
    "    pass  # df already available\n",
    "\n",
    "if 'df' not in globals():\n",
    "    import pandas as _pd\n",
    "    df = _pd.read_csv('train.csv/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72704169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5000 rows\n",
      "Processed 10000 rows\n",
      "Processed 10000 rows\n",
      "Processed 15000 rows\n",
      "Processed 15000 rows\n",
      "Processed 20000 rows\n",
      "Processed 20000 rows\n",
      "Processed 25000 rows\n",
      "Processed 25000 rows\n",
      "Processed 30000 rows\n",
      "Processed 30000 rows\n",
      "Processed 35000 rows\n",
      "Processed 35000 rows\n",
      "Processed 40000 rows\n",
      "Processed 40000 rows\n",
      "Processed 45000 rows\n",
      "Processed 45000 rows\n",
      "Processed 50000 rows\n",
      "Processed 50000 rows\n",
      "Processed 55000 rows\n",
      "Processed 55000 rows\n",
      "Processed 60000 rows\n",
      "Processed 60000 rows\n",
      "Processed 65000 rows\n",
      "Processed 65000 rows\n",
      "Processed 70000 rows\n",
      "Processed 70000 rows\n",
      "Processed 75000 rows\n",
      "Processed 75000 rows\n",
      "Processed 80000 rows\n",
      "Processed 80000 rows\n",
      "Processed 85000 rows\n",
      "Processed 85000 rows\n",
      "Processed 90000 rows\n",
      "Processed 90000 rows\n",
      "Processed 95000 rows\n",
      "Processed 95000 rows\n",
      "Processed 100000 rows\n",
      "Processed 100000 rows\n",
      "Processed 105000 rows\n",
      "Processed 105000 rows\n",
      "Processed 110000 rows\n",
      "Processed 110000 rows\n",
      "Processed 115000 rows\n",
      "Processed 115000 rows\n",
      "Processed 120000 rows\n",
      "Processed 120000 rows\n",
      "Processed 125000 rows\n",
      "Processed 125000 rows\n",
      "Processed 130000 rows\n",
      "Processed 130000 rows\n",
      "Processed 135000 rows\n",
      "Processed 135000 rows\n",
      "Processed 140000 rows\n",
      "Processed 140000 rows\n",
      "Processed 145000 rows\n",
      "Processed 145000 rows\n"
     ]
    }
   ],
   "source": [
    "# Process a sample or full dataset depending on size - here we process all but you can sample: df_sample = df.head(100)\n",
    "ent_lists = []\n",
    "masks = []\n",
    "for i, txt in enumerate(df['comment_text'].fillna('')):\n",
    "    masked, ents = mask_personal_info(txt)\n",
    "    masks.append(masked)\n",
    "    ent_lists.append(ents)\n",
    "    # optional: progress print every 5000 rows to avoid flooding output\n",
    "    if (i + 1) % 5000 == 0:\n",
    "        print(f'Processed {i+1} rows')\n",
    "\n",
    "df['comment_text_masked'] = masks\n",
    "df['masked_entities'] = ent_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1b7c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a few examples\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "print(df[['comment_text', 'comment_text_masked', 'masked_entities']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abce69b2",
   "metadata": {},
   "source": [
    "## Sentiment analysis with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85a4979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/romarickaki/miniforge3/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76157e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/romarickaki/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "nltk.download(\"vader_lexicon\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b9c45fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv/train.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f3a02ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"comment_text\"]\n",
    "y = df[\"toxic\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9f08c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes restantes : 159571\n"
     ]
    }
   ],
   "source": [
    "# Supprimer les lignes où la colonne 'comment_text' est vide ou NaN\n",
    "df = df.dropna(subset=[\"comment_text\"])\n",
    "\n",
    "# Supprimer les lignes où le texte est vide ou seulement des espaces\n",
    "df = df[df[\"comment_text\"].str.strip() != \"\"]\n",
    "\n",
    "print(\"Nombre de lignes restantes :\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de19c5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         comment_text  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                           Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                           Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
      "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 You, sir, are my hero. Any chance you remember what page that's on?   \n",
      "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \"\\n\\nCongratulations from me as well, use the tools well.  · talk \"   \n",
      "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
      "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Your vandalism to the Matt Shirvington article has been reverted.  Please don't do it again, or you will be banned.   \n",
      "8                                                                                                                                                            Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169   \n",
      "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              alignment on this subject and which are contrary to those of DuLithgow   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   comment_text_clean  \n",
      "0                                                                                                                                                                                                                                                                                                                                                      Explanation Why the edits made under my username Hardcore Metallica Fan were reverted They werent vandalisms just closure on some GAs after I voted at New York Dolls FAC And please dont remove the template from the talk page since Im retired now892053827  \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Daww He matches this background colour Im seemingly stuck with Thanks talk 2151 January 11 2016 UTC  \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                 Hey man Im really not trying to edit war Its just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page He seems to care more about the formatting than the actual info  \n",
      "3  More I cant make any real suggestions on improvement I wondered if the section statistics should be later on or a subsection of types of accidents I think the references may need tidying so that they are all in the exact same format ie date format etc I can do that later on if noone else does first if you have any preferences for formatting style on references or want to do it yourself please let me know There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up Its listed in the relevant form eg WikipediaGoodarticlenominationsTransport  \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      You sir are my hero Any chance you remember what page thats on  \n",
      "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Congratulations from me as well use the tools well talk  \n",
      "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK  \n",
      "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Your vandalism to the Matt Shirvington article has been reverted Please dont do it again or you will be banned  \n",
      "8                                                                                                                                               Sorry if the word nonsense was offensive to you Anyway Im not intending to write anything in the articlewow they would jump on me for vandalism Im merely requesting that it be more encyclopedic so one can use it for school as a reference I have been to the selective breeding page but its almost a stub It points to animal breeding which is a short messy article that gives you no info There must be someone around with expertise in eugenics 93161107169  \n",
      "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              alignment on this subject and which are contrary to those of DuLithgow  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Supprimer tout sauf lettres, chiffres et espaces\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', str(text))\n",
    "    # Supprimer les espaces multiples\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "df[\"comment_text_clean\"] = df[\"comment_text\"].apply(clean_text)\n",
    "\n",
    "print(df[[\"comment_text\", \"comment_text_clean\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc2c9043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id  compound predicted_sentiment\n",
      "0  0000997932d777bf    0.5574            positive\n",
      "1  000103f0d9cfb60f    0.2942            positive\n",
      "2  000113f07ec002fd   -0.1779            negative\n",
      "3  0001b41b1c6bb37e    0.5106            positive\n",
      "4  0001d958c54c6e35    0.6808            positive\n",
      "5  00025465d4725e87    0.7964            positive\n",
      "6  0002bcb3da6cb337   -0.7783            negative\n",
      "7  00031b1e95af7921   -0.1779            negative\n",
      "8  00037261f536c51d   -0.8020            negative\n",
      "9  00040093b2687caa    0.0000             neutral\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.to_csv(\"comments_cleaned.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Vader sentiment analyser\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# scores (pos neg neu and compound)\n",
    "df[\"scores\"] = df[\"comment_text\"].apply(lambda x: sia.polarity_scores(str(x)))\n",
    "\n",
    "# score global\n",
    "df[\"compound\"] = df[\"scores\"].apply(lambda d: d[\"compound\"])\n",
    "\n",
    "\n",
    "def sentiment_label(score):\n",
    "    if score >= 0.01:\n",
    "        return \"positive\"\n",
    "    elif score <= -0.01:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "df[\"predicted_sentiment\"] = df[\"compound\"].apply(sentiment_label)\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "\n",
    "print(df[[\"id\", \"compound\", \"predicted_sentiment\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "11a1e1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5497615481509798\n",
      "\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/romarickaki/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/romarickaki/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/romarickaki/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.21      0.73      0.32     15294\n",
      "     neutral       0.00      0.00      0.00         0\n",
      "    positive       0.96      0.53      0.68    144277\n",
      "\n",
      "    accuracy                           0.55    159571\n",
      "   macro avg       0.39      0.42      0.34    159571\n",
      "weighted avg       0.89      0.55      0.65    159571\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11129  1330  2835]\n",
      " [    0     0     0]\n",
      " [42587 25093 76597]]\n"
     ]
    }
   ],
   "source": [
    "# Évaluation\n",
    "# Exemple : convertir pos/neg en positive/negative\n",
    "df[\"toxic_clean\"] = df[\"toxic\"].replace({0: \"positive\", 1: \"negative\"})\n",
    "\n",
    "y_true = df[\"toxic_clean\"]\n",
    "y_pred = df[\"predicted_sentiment\"]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85d554a",
   "metadata": {},
   "source": [
    "## Sentiment analysis with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94460e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using BERT Sentimental Analysis\n",
    "\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "# Modèle DistilBERT pré-entraîné pour sentiment analysis\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Charger ton dataset TSV (exemple : colonnes [\"label\", \"review\"])\n",
    "df = pd.read_csv(\"train.csv/train.csv\", sep=\"\\t\")\n",
    "\n",
    "# Créer un pipeline d'analyse de sentiments\n",
    "sentiment_pipe = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "\n",
    "# Appliquer le modèle aux reviews\n",
    "results = sentiment_pipe(df[\"review\"].tolist(), batch_size=16, truncation=True)\n",
    "\n",
    "# Extraire les prédictions et scores\n",
    "df[\"predicted_sentiment\"] = [r[\"label\"] for r in results]\n",
    "df[\"confidence\"] = [r[\"score\"] for r in results]\n",
    "\n",
    "# Harmoniser les labels réels\n",
    "df[\"label_clean\"] = df[\"label\"].replace({\"pos\": \"POSITIVE\", \"neg\": \"NEGATIVE\"})\n",
    "\n",
    "# Aperçu des résultats\n",
    "print(df[[\"label_clean\", \"review\", \"predicted_sentiment\", \"confidence\"]].head(10))\n",
    "\n",
    "# Tokenisation en batch\n",
    "inputs = tokenizer(\n",
    "    df[\"review\"].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Inférence sans gradient\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "# Classes prédites (batch)\n",
    "predicted_class_ids = logits.argmax(dim=1).tolist()\n",
    "\n",
    "# Convertir les IDs en labels\n",
    "predicted_labels2 = [model.config.id2label[i] for i in predicted_class_ids]\n",
    "\n",
    "# Ajouter les résultats au DataFrame\n",
    "df[\"predicted_sentiment2\"] = predicted_labels2\n",
    "\n",
    "df[\"label_clean2\"] = df[\"label\"].replace({\"pos\": \"POSITIVE\", \"neg\": \"NEGATIVE\"})\n",
    "\n",
    "# Afficher un aperçu\n",
    "print(df[[\"label_clean2\",\"review\",\"predicted_sentiment2\"]].head(10))\n",
    "\n",
    "\n",
    "y2_true = df[\"label_clean2\"]\n",
    "y2_pred = df[\"predicted_sentiment2\"]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y2_true, y2_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y2_true, y2_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y2_true, y2_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
