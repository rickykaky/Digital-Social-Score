#!/bin/bash

# Script de test pour le pipeline ML avec dÃ©ploiement conditionnel
# Usage: ./test_ml_pipeline.sh [seuil_accuracy]

set -e

PROJECT_ID="digital-social-score"
REGION="us-west1"
THRESHOLD=${1:-0.85}

echo "ğŸ¤– TEST DU PIPELINE ML AVEC DÃ‰PLOIEMENT CONDITIONNEL"
echo "=================================================="
echo "Projet: $PROJECT_ID"
echo "RÃ©gion: $REGION" 
echo "Seuil: accuracy â‰¥ $THRESHOLD"
echo ""

# VÃ©rifier les prÃ©requis
echo "ğŸ” VÃ©rification des prÃ©requis..."

# Python et dÃ©pendances
if ! command -v python &> /dev/null; then
    echo "âŒ Python non trouvÃ©"
    exit 1
fi

if ! python -c "import kfp, google.cloud.aiplatform" 2>/dev/null; then
    echo "ğŸ“¦ Installation des dÃ©pendances ML..."
    pip install kfp==2.5.0 google-cloud-aiplatform
fi

# Configuration gcloud
if ! gcloud config get-value project &>/dev/null; then
    echo "âŒ gcloud non configurÃ©"
    echo "ğŸ’¡ ExÃ©cutez: gcloud config set project $PROJECT_ID"
    exit 1
fi

echo "âœ… PrÃ©requis OK"
echo ""

# Test 1: Compilation du pipeline
echo "ğŸ”¨ TEST 1: Compilation du pipeline ML..."
cd src

python trigger_pipeline.py \
    --project $PROJECT_ID \
    --region $REGION \
    --deploy-threshold $THRESHOLD \
    --compile-only

if [ -f "digital_score_pipeline.yaml" ]; then
    echo "âœ… Pipeline compilÃ© avec succÃ¨s"
    echo "ğŸ“„ Fichier gÃ©nÃ©rÃ©: digital_score_pipeline.yaml"
else
    echo "âŒ Erreur compilation pipeline"
    exit 1
fi

echo ""

# Test 2: Validation du fichier YAML
echo "ğŸ“‹ TEST 2: Validation du fichier pipeline..."

if grep -q "deploy_condition" digital_score_pipeline.yaml; then
    echo "âœ… Condition de dÃ©ploiement trouvÃ©e"
else
    echo "âŒ Condition de dÃ©ploiement manquante"
    exit 1
fi

if grep -q "build_and_deploy_docker_op" digital_score_pipeline.yaml; then
    echo "âœ… Composant de dÃ©ploiement Docker trouvÃ©"
else
    echo "âŒ Composant de dÃ©ploiement Docker manquant"
    exit 1
fi

if grep -q "evaluate_model_op" digital_score_pipeline.yaml; then
    echo "âœ… Composant d'Ã©valuation trouvÃ©"
else
    echo "âŒ Composant d'Ã©valuation manquant"
    exit 1
fi

echo "âœ… Fichier pipeline valide"
echo ""

# Test 3: VÃ©rification des paramÃ¨tres
echo "ğŸ¯ TEST 3: VÃ©rification des paramÃ¨tres..."

if grep -q "deploy_threshold.*$THRESHOLD" digital_score_pipeline.yaml; then
    echo "âœ… Seuil de dÃ©ploiement configurÃ©: $THRESHOLD"
else
    echo "âš ï¸  Seuil de dÃ©ploiement non trouvÃ© (peut Ãªtre normal)"
fi

if grep -q "$PROJECT_ID" digital_score_pipeline.yaml; then
    echo "âœ… Project ID configurÃ©: $PROJECT_ID"
else
    echo "âŒ Project ID manquant"
    exit 1
fi

echo "âœ… ParamÃ¨tres OK"
echo ""

# Test 4: Simulation Ã©valuation modÃ¨le
echo "ğŸ“Š TEST 4: Simulation Ã©valuation modÃ¨le..."

cat > test_evaluation.py << 'EOF'
import sys
sys.path.append('.')

def simulate_evaluation(threshold):
    """Simule l'Ã©valuation d'un modÃ¨le"""
    import random
    random.seed(42)
    
    # Simuler diffÃ©rentes accuracies
    test_cases = [0.78, 0.83, 0.87, 0.91, 0.94]
    
    for accuracy in test_cases:
        deploy = accuracy >= threshold
        status = "âœ… DÃ‰PLOIEMENT AUTORISÃ‰" if deploy else "âŒ DÃ‰PLOIEMENT REFUSÃ‰"
        print(f"Accuracy: {accuracy:.3f} | Seuil: {threshold:.3f} | {status}")
    
    return True

if __name__ == "__main__":
    threshold = float(sys.argv[1]) if len(sys.argv) > 1 else 0.85
    simulate_evaluation(threshold)
EOF

python test_evaluation.py $THRESHOLD
rm test_evaluation.py

echo "âœ… Simulation Ã©valuation OK"
echo ""

# Test 5: Test de soumission (dry-run)
echo "ğŸš€ TEST 5: Test de soumission (simulation)..."

echo "ğŸ“‹ Commande qui serait exÃ©cutÃ©e:"
echo "python trigger_pipeline.py \\"
echo "    --project $PROJECT_ID \\"
echo "    --region $REGION \\"
echo "    --deploy-threshold $THRESHOLD \\"
echo "    --display-name 'TEST-ML-Pipeline-$(date +%Y%m%d-%H%M%S)'"

echo ""
echo "ğŸ’¡ Pour exÃ©cuter rÃ©ellement le pipeline:"
echo "cd src && python trigger_pipeline.py --project $PROJECT_ID --region $REGION --deploy-threshold $THRESHOLD"

echo "âœ… Test de soumission OK"
echo ""

# Test 6: VÃ©rification GitHub Actions
echo "ğŸ”„ TEST 6: VÃ©rification GitHub Actions..."

cd ..

if grep -q "ml-pipeline-simulation" .github/workflows/tests.yml; then
    echo "âœ… Job ML pipeline simulation trouvÃ© dans GitHub Actions"
else
    echo "âŒ Job ML pipeline simulation manquant dans GitHub Actions"
    exit 1
fi

if grep -q "THRESHOLD=0.85" .github/workflows/tests.yml; then
    echo "âœ… Seuil configurÃ© dans GitHub Actions"
else
    echo "âš ï¸  Seuil GitHub Actions Ã  vÃ©rifier manuellement"
fi

echo "âœ… GitHub Actions OK"
echo ""

# RÃ©sumÃ©
echo "ğŸ‰ TOUS LES TESTS PASSÃ‰S AVEC SUCCÃˆS!"
echo "=================================================="
echo ""
echo "ğŸ“‹ RÃ©sumÃ© de la configuration:"
echo "   âœ… Pipeline ML compilable"
echo "   âœ… DÃ©ploiement conditionnel configurÃ©"
echo "   âœ… Seuil accuracy: $THRESHOLD"
echo "   âœ… GitHub Actions synchronisÃ©"
echo "   âœ… PrÃªt pour dÃ©ploiement automatique"
echo ""
echo "ğŸš€ Actions suivantes:"
echo "   1. git add . && git commit -m 'feat: pipeline ML conditionnel'"
echo "   2. git push origin main"
echo "   3. Surveiller Console Vertex AI Pipelines"
echo "   4. VÃ©rifier dÃ©ploiement automatique si accuracy â‰¥ $THRESHOLD"
echo ""
echo "ğŸ”— Liens utiles:"
echo "   ğŸ“Š Vertex AI: https://console.cloud.google.com/vertex-ai/pipelines"
echo "   ğŸ³ Cloud Build: https://console.cloud.google.com/cloud-build/builds"
echo "   âš™ï¸  GitHub Actions: https://github.com/rickykaky/Digital-Social-Score/actions"

# Nettoyage
cd src
rm -f digital_score_pipeline.yaml

echo ""
echo "âœ… Test terminÃ© - Pipeline ML prÃªt pour production!"