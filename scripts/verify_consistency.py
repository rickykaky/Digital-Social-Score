#!/usr/bin/env python3
"""
Script de v√©rification de coh√©rence pour le projet Digital Social Score
Fichier: scripts/verify_consistency.py

Ce script v√©rifie que tous les fichiers du projet sont coh√©rents entre eux
et que les configurations, mod√®les, et tests fonctionnent correctement.
"""

import sys
import os
from pathlib import Path
import pandas as pd

# Ajouter src au PYTHONPATH
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

def test_configuration():
    """Test de la configuration centralis√©e"""
    print("üîß Test de la configuration centralis√©e...")
    
    try:
        from config import config
        
        # V√©rifier les patterns d'anonymisation
        assert config.EMAIL_RE.pattern == r'\b[\w\.-]+@[\w\.-]+\.\w{2,}\b'
        print("‚úÖ Patterns EMAIL_RE coh√©rents")
        
        # V√©rifier les colonnes de toxicit√©
        expected_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
        assert config.TOXICITY_COLUMNS == expected_columns
        print("‚úÖ Colonnes de toxicit√© configur√©es")
        
        # V√©rifier les entit√©s nomm√©es
        assert 'PERSON' in config.NAMED_ENTITY_LABELS
        assert 'GPE' in config.NAMED_ENTITY_LABELS
        print("‚úÖ Entit√©s nomm√©es configur√©es")
        
        print("‚úÖ Configuration centralis√©e OK\n")
        return True
    except Exception as e:
        print(f"‚ùå Erreur configuration: {e}\n")
        return False

def test_anonymization_functions():
    """Test des fonctions d'anonymisation"""
    print("üõ°Ô∏è Test des fonctions d'anonymisation...")
    
    try:
        from app import mask_regex_pii, mask_named_entities, anonymize_text
        
        # Test masquage email
        result = mask_regex_pii("Contact me at john@example.com")
        assert "john@example.com" not in result
        assert "<EMAIL>" in result
        print("‚úÖ Masquage email fonctionne")
        
        # Test masquage t√©l√©phone
        result = mask_regex_pii("Call me at 555-1234-5678")
        assert "555-1234-5678" not in result
        assert "<PHONE>" in result
        print("‚úÖ Masquage t√©l√©phone fonctionne")
        
        # Test anonymisation compl√®te
        text = "Hi, I'm John Smith, email me at john@test.com or call 555-123-4567"
        result = anonymize_text(text)
        assert "john@test.com" not in result
        assert "555-123-4567" not in result
        print("‚úÖ Anonymisation compl√®te fonctionne")
        
        print("‚úÖ Fonctions d'anonymisation OK\n")
        return True
    except Exception as e:
        print(f"‚ùå Erreur anonymisation: {e}\n")
        return False

def test_data_consistency():
    """Test de coh√©rence des donn√©es"""
    print("üìä Test de coh√©rence des donn√©es...")
    
    try:
        # V√©rifier que prod.csv existe et a la bonne structure
        data_path = Path(__file__).parent.parent / 'data' / 'prod.csv'
        if not data_path.exists():
            print("‚ö†Ô∏è prod.csv n'existe pas, utilisation du dataset de test")
            return True
        
        df = pd.read_csv(data_path)
        
        # V√©rifier les colonnes requises
        required_cols = ['id', 'comment_text', 'toxic']
        for col in required_cols:
            assert col in df.columns, f"Colonne manquante: {col}"
        print("‚úÖ Colonnes requises pr√©sentes")
        
        # V√©rifier les colonnes de toxicit√© optionnelles
        from config import config
        toxicity_cols = config.get_available_toxicity_columns(df.columns.tolist())
        print(f"‚úÖ Colonnes de toxicit√© disponibles: {toxicity_cols}")
        
        print("‚úÖ Coh√©rence des donn√©es OK\n")
        return True
    except Exception as e:
        print(f"‚ùå Erreur donn√©es: {e}\n")
        return False

def test_model_training():
    """Test d'entra√Ænement du mod√®le"""
    print("ü§ñ Test d'entra√Ænement du mod√®le...")
    
    try:
        from train import train_and_save_model
        from config import config
        
        # Cr√©er un petit dataset de test
        test_data = {
            'comment_text': [
                'This is a great product!',
                'I hate this, terrible service',
                'Awesome experience, highly recommend', 
                'Worst purchase ever, never again',
                'Average, nothing special'
            ],
            'toxic': [0, 1, 0, 1, 0],
            'severe_toxic': [0, 0, 0, 1, 0],
            'obscene': [0, 1, 0, 0, 0],
            'threat': [0, 0, 0, 1, 0],
            'insult': [0, 1, 0, 1, 0],
            'identity_hate': [0, 0, 0, 0, 0]
        }
        
        df = pd.DataFrame(test_data)
        test_file = Path(__file__).parent.parent / 'data' / 'consistency_test.csv'
        df.to_csv(test_file, index=False)
        
        # Entra√Æner le mod√®le
        print("Entra√Ænement en cours...")
        train_and_save_model(str(test_file))
        
        # V√©rifier que les fichiers sont cr√©√©s
        model_path = config.get_model_path()
        vectorizer_path = config.get_vectorizer_path()
        assert model_path.exists(), f"Mod√®le non trouv√©: {model_path}"
        assert vectorizer_path.exists(), f"Vectoriseur non trouv√©: {vectorizer_path}"
        print("‚úÖ Mod√®le et vectoriseur sauvegard√©s")
        
        # Nettoyer
        test_file.unlink()
        
        print("‚úÖ Entra√Ænement du mod√®le OK\n")
        return True
    except Exception as e:
        print(f"‚ùå Erreur entra√Ænement: {e}\n")
        return False

def test_api_functionality():
    """Test des fonctionnalit√©s de l'API"""
    print("üöÄ Test des fonctionnalit√©s de l'API...")
    
    try:
        from app import calculate_score
        
        # Test calcul de score
        score = calculate_score("This is a wonderful day!")
        assert 0 <= score <= 100, f"Score invalide: {score}"
        print(f"‚úÖ Score calcul√©: {score}")
        
        # Test avec du contenu toxique
        toxic_score = calculate_score("This sucks, I hate it!")
        assert 0 <= toxic_score <= 100, f"Score toxique invalide: {toxic_score}"
        print(f"‚úÖ Score toxique calcul√©: {toxic_score}")
        
        print("‚úÖ Fonctionnalit√©s API OK\n")
        return True
    except Exception as e:
        print(f"‚ùå Erreur API: {e}\n")
        return False

def test_unit_tests():
    """Test que les tests unitaires passent"""
    print("üß™ Test des tests unitaires...")
    
    try:
        import subprocess
        import os
        
        # Changer vers le r√©pertoire src pour les imports
        original_cwd = os.getcwd()
        src_dir = Path(__file__).parent.parent / 'src'
        os.chdir(src_dir)
        
        # Ex√©cuter quelques tests cl√©s
        result = subprocess.run([
            'python', '-m', 'pytest', 
            '../tests/unit/test_anonymization.py::TestRegexPatterns::test_email_regex_detection',
            '-v', '--tb=short'
        ], capture_output=True, text=True)
        
        os.chdir(original_cwd)
        
        if result.returncode == 0:
            print("‚úÖ Tests unitaires passent")
            print("‚úÖ Tests unitaires OK\n")
            return True
        else:
            print(f"‚ùå Tests √©chou√©s: {result.stderr}")
            return False
    except Exception as e:
        print(f"‚ùå Erreur tests: {e}\n")
        return False

def main():
    """Fonction principale de v√©rification"""
    print("=" * 60)
    print("üîç V√âRIFICATION DE COH√âRENCE - DIGITAL SOCIAL SCORE")
    print("=" * 60)
    print()
    
    tests = [
        ("Configuration", test_configuration),
        ("Anonymisation", test_anonymization_functions), 
        ("Donn√©es", test_data_consistency),
        ("Mod√®le ML", test_model_training),
        ("API", test_api_functionality),
        ("Tests unitaires", test_unit_tests)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"üîÑ Ex√©cution: {test_name}")
        success = test_func()
        results.append((test_name, success))
    
    print("=" * 60)
    print("üìä R√âSULTATS DE LA V√âRIFICATION")
    print("=" * 60)
    
    all_passed = True
    for test_name, success in results:
        status = "‚úÖ PASS√â" if success else "‚ùå √âCHEC"
        print(f"{test_name:<20}: {status}")
        if not success:
            all_passed = False
    
    print()
    if all_passed:
        print("üéâ TOUTES LES V√âRIFICATIONS ONT R√âUSSI!")
        print("‚úÖ Le projet est coh√©rent et pr√™t pour le d√©ploiement.")
        return 0
    else:
        print("‚ö†Ô∏è CERTAINES V√âRIFICATIONS ONT √âCHOU√â")
        print("‚ùå Veuillez corriger les erreurs avant le d√©ploiement.")
        return 1

if __name__ == "__main__":
    sys.exit(main())